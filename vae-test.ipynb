{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "\n",
    "from cloudcasting.constants import NUM_CHANNELS, DATA_INTERVAL_SPACING_MINUTES\n",
    "\n",
    "from cloud_diffusion.dataset import CloudcastingDataset\n",
    "from cloud_diffusion.utils import set_seed\n",
    "from cloud_diffusion.ddpm import noisify_ddpm, ddim_sampler\n",
    "from cloud_diffusion.models import UNet2D\n",
    "from cloud_diffusion.vae import TemporalVAEAdapter\n",
    "\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastprogress import progress_bar\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "channel_names = ['IR_016', 'IR_039', 'IR_087', 'IR_097', 'IR_108', 'IR_120', 'IR_134',\n",
    "       'VIS006', 'VIS008', 'WV_062', 'WV_073']\n",
    "\n",
    "PROJECT_NAME = \"nathan-test\"\n",
    "MERGE_CHANNELS = False\n",
    "DEBUG = True\n",
    "LOCAL = False\n",
    "\n",
    "config = SimpleNamespace(\n",
    "    img_size=256,\n",
    "    epochs=50,  # number of epochs\n",
    "    model_name=\"uvit-test\",  # model name to save [unet_small, unet_big]\n",
    "    strategy=\"ddpm\",  # strategy to use [ddpm, simple_diffusion]\n",
    "    noise_steps=1000,  # number of noise steps on the diffusion process\n",
    "    sampler_steps=300,  # number of sampler steps on the diffusion process\n",
    "    seed=42,  # random seed\n",
    "    batch_size=2,  # batch size\n",
    "    device=\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    num_workers=0 if DEBUG else 35,  # number of workers for dataloader\n",
    "    num_frames=4,  # number of frames to use as input (includes noise frame)\n",
    "    lr=5e-4,  # learning rate\n",
    "    log_every_epoch=1,  # log every n epochs to wandb\n",
    "    n_preds=8,  # number of predictions to make\n",
    "    latent_dim=4,\n",
    "    vae_lr=5e-5,\n",
    ")\n",
    "\n",
    "device = config.device\n",
    "\n",
    "\n",
    "HISTORY_STEPS = config.num_frames - 1\n",
    "\n",
    "\n",
    "config.model_params = dict(\n",
    "    block_out_channels=(32, 64, 128, 256),  # number of channels for each block\n",
    "    norm_num_groups=8,  # number of groups for the normalization layer\n",
    "    in_channels=config.num_frames * config.latent_dim,  # number of input channels\n",
    "    out_channels=config.latent_dim,  # number of output channels\n",
    ")\n",
    "\n",
    "set_seed(config.seed)\n",
    "\n",
    "if LOCAL:\n",
    "    TRAINING_DATA_PATH = VALIDATION_DATA_PATH = \"/users/nsimpson/Code/climetrend/cloudcast/2020_training_nonhrv.zarr\"\n",
    "else:\n",
    "    TRAINING_DATA_PATH = \"/bask/projects/v/vjgo8416-climate/shared/data/eumetsat/training/2021_nonhrv.zarr\"\n",
    "    VALIDATION_DATA_PATH = \"/bask/projects/v/vjgo8416-climate/shared/data/eumetsat/training/2022_training_nonhrv.zarr\"\n",
    "# Instantiate the torch dataset object\n",
    "train_ds = CloudcastingDataset(\n",
    "    config.img_size,\n",
    "    valid=False,\n",
    "    # strategy=\"resize\",\n",
    "    zarr_path=TRAINING_DATA_PATH,\n",
    "    start_time=None,\n",
    "    end_time=None,\n",
    "    history_mins=(HISTORY_STEPS - 1) * DATA_INTERVAL_SPACING_MINUTES,\n",
    "    forecast_mins=15,\n",
    "    sample_freq_mins=15,\n",
    "    nan_to_num=False,\n",
    "    merge_channels=MERGE_CHANNELS,\n",
    ")\n",
    "# worth noting they do some sort of shuffling here; we don't for now\n",
    "valid_ds = CloudcastingDataset(\n",
    "    config.img_size,\n",
    "    valid=True,\n",
    "    # strategy=\"resize\",\n",
    "    zarr_path=VALIDATION_DATA_PATH,\n",
    "    start_time=None,\n",
    "    end_time=None,\n",
    "    history_mins=(HISTORY_STEPS - 1) * DATA_INTERVAL_SPACING_MINUTES,\n",
    "    forecast_mins=15,\n",
    "    sample_freq_mins=15,\n",
    "    nan_to_num=False,\n",
    "    merge_channels=MERGE_CHANNELS,\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_ds, config.batch_size, shuffle=True,  num_workers=config.num_workers, pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_ds, config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(iter(train_dataloader))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 11, 4, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# model setup\n",
    "unet = UNet2D(**config.model_params).to(device)\n",
    "# vae = get_hacked_vae().to(device)#.float()\n",
    "from diffusers.models import AutoencoderKL\n",
    "vae = TemporalVAEAdapter(AutoencoderKL.from_pretrained(\"stabilityai/sdxl-vae\").to(device)).to(device)\n",
    "\n",
    "# vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\").to(device).float()\n",
    "# for param in vae.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# sampler\n",
    "sampler = ddim_sampler(steps=config.sampler_steps)\n",
    "\n",
    "# configure training\n",
    "# wandb.config.update(config)\n",
    "config.total_train_steps = config.epochs * len(train_dataloader)\n",
    "\n",
    "# Create parameter groups with different learning rates\n",
    "param_groups = [\n",
    "    {\n",
    "        'params': [p for p in vae.parameters() if p.requires_grad],\n",
    "        'lr': config.vae_lr,\n",
    "        'eps': 1e-5\n",
    "    },\n",
    "    {\n",
    "        'params': unet.parameters(),\n",
    "        'lr': config.lr,\n",
    "        'eps': 1e-5\n",
    "    }\n",
    "]\n",
    "optimizer = AdamW(param_groups)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=[config.vae_lr, config.lr], total_steps=config.total_train_steps)\n",
    "scaler = torch.amp.GradScaler(\"cuda\")\n",
    "\n",
    "# get a validation batch for logging\n",
    "val_batch = next(iter(valid_dataloader))[0:2].to(device)  # log first 2 predictions\n",
    "print(val_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/50 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='29' class='' max='14687' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.20% [29/14687 01:36&lt;13:33:28 epoch=0, vae_loss=0.427, diffusion_loss=1.022]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_batch stats: min=-0.978, max=0.921, mean=0.040, std=0.662\n",
      "latents stats: min=-1.678, max=2.776, mean=0.487, std=0.686\n",
      "predicted_noise stats: min=-0.040, max=0.021, mean=-0.015, std=0.025\n",
      "img_batch stats: min=-0.978, max=0.912, mean=0.086, std=0.643\n",
      "latents stats: min=-1.742, max=2.802, mean=0.516, std=0.719\n",
      "predicted_noise stats: min=-0.041, max=0.021, mean=-0.014, std=0.025\n",
      "img_batch stats: min=-0.977, max=0.907, mean=0.104, std=0.571\n",
      "latents stats: min=-1.606, max=2.796, mean=0.502, std=0.715\n",
      "predicted_noise stats: min=-0.041, max=0.022, mean=-0.014, std=0.025\n",
      "img_batch stats: min=-0.977, max=0.925, mean=0.114, std=0.585\n",
      "latents stats: min=-1.762, max=2.639, mean=0.495, std=0.700\n",
      "predicted_noise stats: min=-0.041, max=0.022, mean=-0.014, std=0.025\n",
      "img_batch stats: min=-0.977, max=0.932, mean=0.106, std=0.632\n",
      "latents stats: min=-1.678, max=2.797, mean=0.526, std=0.696\n",
      "predicted_noise stats: min=-0.042, max=0.023, mean=-0.014, std=0.024\n",
      "img_batch stats: min=-0.978, max=0.997, mean=0.076, std=0.622\n",
      "latents stats: min=-1.782, max=2.679, mean=0.483, std=0.690\n",
      "predicted_noise stats: min=-0.042, max=0.024, mean=-0.014, std=0.024\n",
      "img_batch stats: min=-0.938, max=0.918, mean=0.177, std=0.500\n",
      "latents stats: min=-1.724, max=2.768, mean=0.512, std=0.700\n",
      "predicted_noise stats: min=-0.043, max=0.025, mean=-0.014, std=0.024\n",
      "img_batch stats: min=-0.977, max=0.938, mean=0.181, std=0.576\n",
      "latents stats: min=-1.665, max=2.864, mean=0.502, std=0.714\n",
      "predicted_noise stats: min=-0.042, max=0.025, mean=-0.014, std=0.023\n",
      "img_batch stats: min=-0.977, max=0.932, mean=0.173, std=0.616\n",
      "latents stats: min=-1.749, max=2.791, mean=0.515, std=0.725\n",
      "predicted_noise stats: min=-0.041, max=0.024, mean=-0.013, std=0.023\n",
      "img_batch stats: min=-0.935, max=0.901, mean=0.120, std=0.533\n",
      "latents stats: min=-1.811, max=2.784, mean=0.516, std=0.707\n",
      "predicted_noise stats: min=-0.043, max=0.025, mean=-0.013, std=0.023\n",
      "img_batch stats: min=-0.978, max=0.946, mean=0.167, std=0.610\n",
      "latents stats: min=-1.869, max=2.690, mean=0.504, std=0.719\n",
      "predicted_noise stats: min=-0.044, max=0.026, mean=-0.013, std=0.023\n",
      "img_batch stats: min=-0.952, max=0.924, mean=0.160, std=0.555\n",
      "latents stats: min=-1.687, max=2.714, mean=0.523, std=0.693\n",
      "predicted_noise stats: min=-0.044, max=0.027, mean=-0.013, std=0.022\n",
      "img_batch stats: min=-0.939, max=0.943, mean=0.177, std=0.530\n",
      "latents stats: min=-1.726, max=2.863, mean=0.516, std=0.673\n",
      "predicted_noise stats: min=-0.044, max=0.028, mean=-0.012, std=0.022\n",
      "img_batch stats: min=-0.977, max=0.929, mean=0.179, std=0.574\n",
      "latents stats: min=-1.753, max=2.803, mean=0.507, std=0.673\n",
      "predicted_noise stats: min=-0.046, max=0.031, mean=-0.012, std=0.022\n",
      "img_batch stats: min=-0.977, max=0.903, mean=0.001, std=0.650\n",
      "latents stats: min=-1.497, max=2.738, mean=0.491, std=0.705\n",
      "predicted_noise stats: min=-0.048, max=0.030, mean=-0.012, std=0.022\n",
      "img_batch stats: min=-0.978, max=0.924, mean=0.136, std=0.601\n",
      "latents stats: min=-1.694, max=2.728, mean=0.496, std=0.681\n",
      "predicted_noise stats: min=-0.045, max=0.028, mean=-0.012, std=0.021\n",
      "img_batch stats: min=-0.977, max=0.918, mean=0.049, std=0.668\n",
      "latents stats: min=-1.902, max=2.802, mean=0.468, std=0.741\n",
      "predicted_noise stats: min=-0.047, max=0.032, mean=-0.012, std=0.022\n",
      "img_batch stats: min=-0.939, max=0.938, mean=0.189, std=0.509\n",
      "latents stats: min=-1.675, max=2.762, mean=0.528, std=0.649\n",
      "predicted_noise stats: min=-0.049, max=0.031, mean=-0.012, std=0.022\n",
      "img_batch stats: min=-0.943, max=0.921, mean=0.133, std=0.543\n",
      "latents stats: min=-1.450, max=2.939, mean=0.538, std=0.703\n",
      "predicted_noise stats: min=-0.049, max=0.033, mean=-0.012, std=0.022\n",
      "img_batch stats: min=-0.978, max=0.919, mean=-0.003, std=0.649\n",
      "latents stats: min=-1.828, max=2.826, mean=0.481, std=0.683\n",
      "predicted_noise stats: min=-0.051, max=0.035, mean=-0.012, std=0.022\n",
      "img_batch stats: min=-0.978, max=0.932, mean=0.110, std=0.662\n",
      "latents stats: min=-1.614, max=2.575, mean=0.479, std=0.695\n",
      "predicted_noise stats: min=-0.050, max=0.039, mean=-0.011, std=0.021\n",
      "img_batch stats: min=-0.977, max=0.937, mean=0.149, std=0.562\n",
      "latents stats: min=-1.550, max=2.779, mean=0.502, std=0.651\n",
      "predicted_noise stats: min=-0.055, max=0.036, mean=-0.011, std=0.022\n",
      "img_batch stats: min=-0.977, max=0.936, mean=0.158, std=0.612\n",
      "latents stats: min=-1.713, max=2.705, mean=0.510, std=0.696\n",
      "predicted_noise stats: min=-0.055, max=0.036, mean=-0.011, std=0.021\n",
      "img_batch stats: min=-0.977, max=0.948, mean=0.131, std=0.620\n",
      "latents stats: min=-1.699, max=2.965, mean=0.523, std=0.722\n",
      "predicted_noise stats: min=-0.056, max=0.036, mean=-0.011, std=0.021\n",
      "img_batch stats: min=-0.948, max=0.935, mean=0.165, std=0.567\n",
      "latents stats: min=-1.775, max=2.764, mean=0.520, std=0.718\n",
      "predicted_noise stats: min=-0.054, max=0.038, mean=-0.011, std=0.022\n",
      "img_batch stats: min=-0.977, max=0.926, mean=0.046, std=0.602\n",
      "latents stats: min=-2.016, max=2.832, mean=0.492, std=0.749\n",
      "predicted_noise stats: min=-0.056, max=0.041, mean=-0.011, std=0.022\n",
      "img_batch stats: min=-0.977, max=0.922, mean=0.133, std=0.596\n",
      "latents stats: min=-1.640, max=2.951, mean=0.518, std=0.710\n",
      "predicted_noise stats: min=-0.061, max=0.038, mean=-0.010, std=0.021\n",
      "img_batch stats: min=-0.978, max=1.000, mean=0.134, std=0.591\n",
      "latents stats: min=-1.814, max=2.835, mean=0.498, std=0.684\n",
      "predicted_noise stats: min=-0.058, max=0.039, mean=-0.010, std=0.021\n",
      "img_batch stats: min=-0.977, max=0.894, mean=0.023, std=0.654\n",
      "latents stats: min=-1.518, max=2.692, mean=0.483, std=0.717\n",
      "predicted_noise stats: min=-0.058, max=0.045, mean=-0.010, std=0.021\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m unet\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     22\u001b[0m pbar \u001b[38;5;241m=\u001b[39m progress_bar(train_dataloader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/fastprogress/fastprogress.py:41\u001b[0m, in \u001b[0;36mProgressBar.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/bask/projects/v/vjgo8416-climate/users/gmmg6904/cloud_diffusion/cloud_diffusion/dataset.py:67\u001b[0m, in \u001b[0;36mCloudcastingDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# concatenate future prediction and previous frames along time axis\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     concat_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((x, y), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# concat_data = np.concatenate((x, y), axis=-3)[self._idxs[idx]]\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# data is in [0,1] range, normalize to [-0.5, 0.5]\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# note that -1s could be NaNs, which are now at +1.5\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# output has shape (11 (if merge_channels is False), history_steps + forecast_horizon, height, width)\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/jaxtyping/_decorator.py:449\u001b[0m, in \u001b[0;36mjaxtyped.<locals>.wrapped_fn_impl\u001b[0;34m(args, kwargs, bound, memos)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m TypeCheckError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Actually call the function.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_signature\u001b[38;5;241m.\u001b[39mreturn_annotation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mSignature\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# Now type-check the return value. We need to include the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# parameters in the type-checking here in case there are any\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# checking of the parameters. Unfortunately there doesn't seem\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# to be a way around that, so c'est la vie.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     kwargs[output_name] \u001b[38;5;241m=\u001b[39m out\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/cloudcasting/dataset.py:194\u001b[0m, in \u001b[0;36mSatelliteDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    191\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(key)\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m t0 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt0_times\n\u001b[0;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt0\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/jaxtyping/_decorator.py:449\u001b[0m, in \u001b[0;36mjaxtyped.<locals>.wrapped_fn_impl\u001b[0;34m(args, kwargs, bound, memos)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m TypeCheckError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Actually call the function.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_signature\u001b[38;5;241m.\u001b[39mreturn_annotation \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mSignature\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# Now type-check the return value. We need to include the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# parameters in the type-checking here in case there are any\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;66;03m# checking of the parameters. Unfortunately there doesn't seem\u001b[39;00m\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;66;03m# to be a way around that, so c'est la vie.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m     kwargs[output_name] \u001b[38;5;241m=\u001b[39m out\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/cloudcasting/dataset.py:167\u001b[0m, in \u001b[0;36mSatelliteDataset._get_datetime\u001b[0;34m(self, t0)\u001b[0m\n\u001b[1;32m    158\u001b[0m ds_sel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39msel(\n\u001b[1;32m    159\u001b[0m     time\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mslice\u001b[39m(\n\u001b[1;32m    160\u001b[0m         t0 \u001b[38;5;241m-\u001b[39m timedelta(minutes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory_mins),\n\u001b[1;32m    161\u001b[0m         t0 \u001b[38;5;241m+\u001b[39m timedelta(minutes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforecast_mins),\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Load the data eagerly so that the same chunks aren't loaded multiple times after we split\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# further\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m ds_sel \u001b[38;5;241m=\u001b[39m \u001b[43mds_sel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msingle-threaded\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Reshape to (channel, time, height, width)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m ds_sel \u001b[38;5;241m=\u001b[39m ds_sel\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_geostationary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_geostationary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/xarray/core/dataset.py:1046\u001b[0m, in \u001b[0;36mDataset.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Manually trigger loading and/or computation of this dataset's data\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03mfrom disk or a remote source into memory and return a new dataset.\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;124;03mUnlike load, the original dataset is left unaltered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;124;03mdask.compute\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/xarray/core/dataset.py:873\u001b[0m, in \u001b[0;36mDataset.load\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    870\u001b[0m chunkmanager \u001b[38;5;241m=\u001b[39m get_chunked_array_type(\u001b[38;5;241m*\u001b[39mlazy_data\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    872\u001b[0m \u001b[38;5;66;03m# evaluate all the chunked arrays simultaneously\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m evaluated_data: \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, Any], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mchunkmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlazy_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(lazy_data, evaluated_data, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables[k]\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/xarray/namedarray/daskmanager.py:86\u001b[0m, in \u001b[0;36mDaskManager.compute\u001b[0;34m(self, *data, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mdata: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray[Any, _DType_co], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compute\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/dask/base.py:660\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 660\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/xarray/core/indexing.py:578\u001b[0m, in \u001b[0;36mImplicitToExplicitIndexingAdapter.__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m, dtype: np\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39m, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Version(np\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 578\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_duck_array(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/xarray/core/indexing.py:583\u001b[0m, in \u001b[0;36mImplicitToExplicitIndexingAdapter.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/xarray/core/indexing.py:794\u001b[0m, in \u001b[0;36mCopyOnWriteArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/xarray/core/indexing.py:657\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    653\u001b[0m     array \u001b[38;5;241m=\u001b[39m apply_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey)\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[0;32m--> 657\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/xarray/backends/zarr.py:166\u001b[0m, in \u001b[0;36mZarrArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, indexing\u001b[38;5;241m.\u001b[39mOuterIndexer):\n\u001b[1;32m    165\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oindex\n\u001b[0;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplicit_indexing_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexingSupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVECTORIZED\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/xarray/core/indexing.py:1018\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[1;32m    997\u001b[0m \n\u001b[1;32m    998\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m-> 1018\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mraw_indexing_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m     indexable \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(result)\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/xarray/backends/zarr.py:156\u001b[0m, in \u001b[0;36mZarrArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/zarr/core.py:795\u001b[0m, in \u001b[0;36mArray.__getitem__\u001b[0;34m(self, selection)\u001b[0m\n\u001b[1;32m    793\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvindex[selection]\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_pure_orthogonal_indexing(pure_selection, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim):\n\u001b[0;32m--> 795\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_orthogonal_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpure_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_basic_selection(pure_selection, fields\u001b[38;5;241m=\u001b[39mfields)\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/zarr/core.py:1077\u001b[0m, in \u001b[0;36mArray.get_orthogonal_selection\u001b[0;34m(self, selection, out, fields)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;66;03m# setup indexer\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m indexer \u001b[38;5;241m=\u001b[39m OrthogonalIndexer(selection, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1077\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/zarr/core.py:1340\u001b[0m, in \u001b[0;36mArray._get_selection\u001b[0;34m(self, indexer, out, fields)\u001b[0m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m math\u001b[38;5;241m.\u001b[39mprod(out_shape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1338\u001b[0m     \u001b[38;5;66;03m# allow storage to get multiple items at once\u001b[39;00m\n\u001b[1;32m   1339\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mindexer)\n\u001b[0;32m-> 1340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chunk_getitems\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlchunk_coords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlchunk_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlout_selection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m   1349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/zarr/core.py:2181\u001b[0m, in \u001b[0;36mArray._chunk_getitems\u001b[0;34m(self, lchunk_coords, lchunk_selection, out, lout_selection, drop_axes, fields)\u001b[0m\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta_array, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   2180\u001b[0m         contexts \u001b[38;5;241m=\u001b[39m ConstantMap(ckeys, constant\u001b[38;5;241m=\u001b[39mContext(meta_array\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta_array))\n\u001b[0;32m-> 2181\u001b[0m     cdatas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ckey, chunk_select, out_select \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ckeys, lchunk_selection, lout_selection):\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ckey \u001b[38;5;129;01min\u001b[39;00m cdatas:\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/zarr/_storage/store.py:179\u001b[0m, in \u001b[0;36mBaseStore.getitems\u001b[0;34m(self, keys, contexts)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetitems\u001b[39m(\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m, keys: Sequence[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39m, contexts: Mapping[\u001b[38;5;28mstr\u001b[39m, Context]\n\u001b[1;32m    156\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    157\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve data from multiple keys.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;124;03m    keys and/or to utilize the contexts.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/zarr/storage.py:1118\u001b[0m, in \u001b[0;36mDirectoryStore.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1116\u001b[0m filepath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath, key)\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(filepath):\n\u001b[0;32m-> 1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "File \u001b[0;32m~/forecasting-space/users/gmmg6904/cloud_diffusion/.venv/lib/python3.12/site-packages/zarr/storage.py:1093\u001b[0m, in \u001b[0;36mDirectoryStore._fromfile\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read data from a file\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \n\u001b[1;32m   1082\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;124;03mfile reading logic.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "vae_loss_scale = 1\n",
    "\n",
    "def check_tensor(tensor, name, print_stats=False):\n",
    "    \"\"\"Utility function to check tensor for NaN/Inf values and optionally print statistics\"\"\"\n",
    "    if torch.isnan(tensor).any():\n",
    "        print(f\"NaN detected in {name}\")\n",
    "        return False\n",
    "    if torch.isinf(tensor).any():\n",
    "        print(f\"Inf detected in {name}\")\n",
    "        return False\n",
    "    if print_stats:\n",
    "        print(f\"{name} stats: min={tensor.min().item():.3f}, max={tensor.max().item():.3f}, \"\n",
    "              f\"mean={tensor.mean().item():.3f}, std={tensor.std().item():.3f}\")\n",
    "    return True\n",
    "\n",
    "# Modified training loop with checks\n",
    "for epoch in progress_bar(range(config.epochs), total=config.epochs, leave=True):\n",
    "    unet.train()\n",
    "    pbar = progress_bar(train_dataloader, leave=False)\n",
    "    for batch in pbar:\n",
    "        if torch.isnan(batch).all():\n",
    "            continue\n",
    "            \n",
    "        # Check input batch\n",
    "        batch = torch.nan_to_num(batch, nan=0)\n",
    "        img_batch = batch.to(device)\n",
    "        check_tensor(img_batch, \"img_batch\", print_stats=True)\n",
    "        \n",
    "    # with torch.autocast(device):\n",
    "        # VAE encoding check\n",
    "        latents = vae.encode_frames(img_batch)\n",
    "        if not check_tensor(latents, \"latents\", print_stats=True):\n",
    "            print(\"NaN detected after VAE encoding\")\n",
    "            break\n",
    "            \n",
    "        # Diffusion preparation checks\n",
    "        past_frames = latents[:, :, :-1]\n",
    "        last_frame = latents[:, :, -1]\n",
    "        check_tensor(past_frames, \"past_frames\")\n",
    "        check_tensor(last_frame, \"last_frame\")\n",
    "        \n",
    "        # Noise addition check\n",
    "        noised_img, t, noise = noisify_ddpm(last_frame)\n",
    "        check_tensor(noised_img, \"noised_img\")\n",
    "        check_tensor(noise, \"noise\")\n",
    "        \n",
    "        # Check reshape operations\n",
    "        past_frames = past_frames.permute(0, 2, 1, 3, 4)\n",
    "        past_frames = past_frames.reshape(latents.shape[0], -1, latents.shape[3], latents.shape[4])\n",
    "        check_tensor(past_frames, \"reshaped_past_frames\")\n",
    "        \n",
    "        # Check concatenated input\n",
    "        diffusion_input = torch.cat([past_frames, noised_img], dim=1)\n",
    "        check_tensor(diffusion_input, \"diffusion_input\")\n",
    "        \n",
    "        # Check UNet output\n",
    "        predicted_noise = unet(diffusion_input, t)\n",
    "        if not check_tensor(predicted_noise, \"predicted_noise\", print_stats=True):\n",
    "            print(\"NaN detected in UNet output\")\n",
    "            break\n",
    "        \n",
    "        # Loss calculation checks\n",
    "        diffusion_loss = F.mse_loss(predicted_noise, noise)\n",
    "        check_tensor(diffusion_loss, \"diffusion_loss\")\n",
    "        \n",
    "        img_batch_hat = vae.decode_frames(latents)\n",
    "        check_tensor(img_batch_hat, \"decoded_frames\")\n",
    "        \n",
    "        vae_loss = F.mse_loss(img_batch_hat, img_batch)\n",
    "        check_tensor(vae_loss, \"vae_loss\")\n",
    "        \n",
    "        loss = diffusion_loss + vae_loss * vae_loss_scale\n",
    "        if not check_tensor(loss, \"total_loss\"):\n",
    "            print(\"NaN detected in final loss\")\n",
    "            break\n",
    "        \n",
    "        # Gradient checking\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # # Check gradients before optimizer step\n",
    "        # for name, param in unet.named_parameters():\n",
    "        #     if param.grad is not None:\n",
    "        #         if not check_tensor(param.grad, f\"gradient_{name}\"):\n",
    "        #             print(f\"NaN gradient detected in {name}\")\n",
    "        #             break\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "        \n",
    "        pbar.comment = f\"epoch={epoch}, vae_loss={vae_loss.item():2.3f}, diffusion_loss={diffusion_loss.item():2.3f}\"\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_latents = vae.encode_frames(val_batch)\n",
    "        past_val_frames = val_latents[:, :, :-1]\n",
    "        last_val_frame = val_latents[:, :, -1]  # intentionally remove time dim\n",
    "        past_val_frames = past_val_frames.permute(0, 2, 1, 3, 4).reshape(val_latents.shape[0], -1, val_latents.shape[3], val_latents.shape[4]).float()\n",
    "        samples = sampler(unet, past_frames=past_val_frames, num_channels=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # log predictions\n",
    "    # if epoch % config.log_every_epoch == 0:\n",
    "    #     samples = ...\n",
    "    #     log_images(val_batch, samples)\n",
    "\n",
    "# save_model(vae, config.model_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_frame.shape=torch.Size([2, 4, 32, 32])\n",
      "past_frames.shape=torch.Size([2, 12, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/300 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    val_latents = vae.encode_frames(val_batch)\n",
    "    past_val_frames = val_latents[:, :, :-1]\n",
    "    last_val_frame = val_latents[:, :, -1]  # intentionally remove time dim\n",
    "    past_val_frames = past_val_frames.permute(0, 2, 1, 3, 4).reshape(val_latents.shape[0], -1, val_latents.shape[3], val_latents.shape[4])\n",
    "    samples = sampler(unet, past_frames=past_val_frames, num_channels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_channels_over_time(images,  batch_idx=0, figsize=(12, 8), cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Visualize multi-channel images over time, handling both single and multiple timesteps.\n",
    "    \n",
    "    Args:\n",
    "        images: Tensor of shape (batch, channels, time, height, width)\n",
    "        channel_names: List of names for each channel\n",
    "        batch_idx: Which batch element to visualize\n",
    "        figsize: Size of the figure\n",
    "        cmap: Colormap to use for visualization\n",
    "    \"\"\"\n",
    "    n_channels = images.shape[1]\n",
    "    n_timesteps = images.shape[2]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create a grid of subplots\n",
    "    if n_timesteps == 1:\n",
    "        fig, axes = plt.subplots(n_channels, 1, figsize=figsize)\n",
    "        axes = axes.reshape(-1, 1)  # Reshape to 2D array for consistent indexing\n",
    "    else:\n",
    "        fig, axes = plt.subplots(n_channels, n_timesteps, figsize=figsize)\n",
    "    \n",
    "    # Set the spacing between subplots\n",
    "    plt.subplots_adjust(hspace=0.2, wspace=-0.5)\n",
    "    \n",
    "    # Iterate through channels and timesteps\n",
    "    for channel in range(n_channels):\n",
    "        for timestep in range(n_timesteps):\n",
    "            # Get the current image\n",
    "            img = images[batch_idx, channel, timestep].numpy()\n",
    "            \n",
    "            # Normalize the image for better visualization\n",
    "            # img_min = img.min()\n",
    "            # img_max = img.max()\n",
    "            # if img_max > img_min:\n",
    "            #     img = (img - img_min) / (img_max - img_min)\n",
    "            \n",
    "            # Plot the image\n",
    "            im = axes[channel, timestep].imshow(img, cmap=cmap, origin='lower')\n",
    "            axes[channel, timestep].axis('off')\n",
    "            \n",
    "            # Add colorbar\n",
    "            plt.colorbar(im, ax=axes[channel, timestep], fraction=0.046, pad=0.04)\n",
    "            \n",
    "            # Add titles\n",
    "            if channel == 0:\n",
    "                axes[channel, timestep].set_title(f'frame {timestep-3}')\n",
    "            if timestep == 0:\n",
    "                axes[channel, timestep].text(-10, 32, channel_names[channel], \n",
    "                                          rotation=0, ha='right', va='center')\n",
    "\n",
    "    return fig\n",
    "visualize_channels_over_time(X);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
